{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent = 'CoolBot/0.0 (https://example.org/coolbot/; coolbot@example.org)'\n",
    "\n",
    "sparqlwd = SPARQLWrapper(\"https://query.wikidata.org/sparql\", agent=user_agent)\n",
    "sparqlwd.setReturnFormat(JSON)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extracting extra info from wikidata (make this separate file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_unified_person_df = pd.read_parquet('tables/tables_52_88/new_unified_person_df_final.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_f=lambda Q:\"\"\"\n",
    "SELECT ?item ?itemLabel\n",
    "WHERE \n",
    "{\n",
    "wd:\"\"\"+Q+\"\"\" wdt:P21 ?item;\n",
    "SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n",
    "}\"\"\"\n",
    "\n",
    "religion_f=lambda Q:\"\"\"\n",
    "SELECT ?item ?itemLabel\n",
    "WHERE \n",
    "{\n",
    "wd:\"\"\"+Q+\"\"\" wdt:P140 ?item.\n",
    "SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n",
    "}\"\"\"\n",
    "\n",
    "educated_f=lambda Q:\"\"\"\n",
    "SELECT ?item ?itemLabel\n",
    "WHERE \n",
    "{\n",
    "wd:\"\"\"+Q+\"\"\" wdt:P69 ?item.\n",
    "SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n",
    "}\"\"\"\n",
    "\n",
    "occupation_f=lambda Q:\"\"\"\n",
    "SELECT ?item ?itemLabel\n",
    "WHERE \n",
    "{\n",
    "wd:\"\"\"+Q+\"\"\" wdt:P106 ?item.\n",
    "SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n",
    "}\"\"\"\n",
    "\n",
    "citizenship_f=lambda Q:\"\"\"\n",
    "SELECT ?item ?itemLabel ?startyearLabel ?endyearLabel\n",
    "WHERE \n",
    "{\n",
    "wd:\"\"\"+Q+\"\"\" p:P27 ?statement1.\n",
    "?statement1 ps:P27 ?item.\n",
    "OPTIONAL{?statement1 pq:P580 ?startyear.}\n",
    "OPTIONAL{?statement1 pq:P582 ?endyear.}\n",
    "SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n",
    "}\"\"\"\n",
    "\n",
    "party_f=lambda Q:\"\"\"\n",
    "SELECT ?item ?itemLabel ?startyearLabel ?endyearLabel\n",
    "WHERE \n",
    "{\n",
    "wd:\"\"\"+Q+\"\"\" p:P102 ?statement1.\n",
    "?statement1 ps:P102 ?item.\n",
    "OPTIONAL{?statement1 pq:P580 ?startyear.}\n",
    "OPTIONAL{?statement1 pq:P582 ?endyear.}\n",
    "SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n",
    "}\"\"\"\n",
    "\n",
    "memberof_f=lambda Q:\"\"\"\n",
    "SELECT ?item ?itemLabel ?startyearLabel ?endyearLabel\n",
    "WHERE \n",
    "{\n",
    "wd:\"\"\"+Q+\"\"\" p:P463 ?statement1.\n",
    "?statement1 ps:P463 ?item.\n",
    "OPTIONAL{?statement1 pq:P580 ?startyear.}\n",
    "OPTIONAL{?statement1 pq:P582 ?endyear.}\n",
    "SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n",
    "}\"\"\"\n",
    "\n",
    "positionheld_f=lambda Q:\"\"\"\n",
    "SELECT ?item ?itemLabel ?startyearLabel ?endyearLabel\n",
    "WHERE \n",
    "{\n",
    "wd:\"\"\"+Q+\"\"\" p:P39 ?statement1.\n",
    "?statement1 ps:P39 ?item.\n",
    "OPTIONAL{?statement1 pq:P580 ?startyear.}\n",
    "OPTIONAL{?statement1 pq:P582 ?endyear.}\n",
    "SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n",
    "}\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_dict={'gender':gender_f,\n",
    "               'religion':religion_f,\n",
    "               'educated':educated_f,\n",
    "               'occupation':occupation_f,\n",
    "               'positionheld':positionheld_f,\n",
    "               'citizenship':citizenship_f,\n",
    "               'memberof':memberof_f,\n",
    "               'party':party_f}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_query(type,entity):\n",
    "\n",
    "    try:\n",
    "        sparqlwd.setQuery(function_dict[type](entity))\n",
    "\n",
    "        return sparqlwd.query().convert()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'name: {entity}')\n",
    "        print(f'error message: {e}')\n",
    "        return {'head': {'vars': ['item']}, 'results': {'bindings': []}}\n",
    "\n",
    "\n",
    "def process_query(row,type):\n",
    "    \n",
    "    entity = row['selected_wiki_entity']\n",
    "\n",
    "    retrieved = []\n",
    "\n",
    "    if entity:\n",
    "\n",
    "        entity = entity.split('/')[-1]\n",
    "\n",
    "        res = execute_query(type,entity)\n",
    "\n",
    "        for binding in res['results']['bindings']:\n",
    "            temp = []\n",
    "            temp.append(binding['item']['value'])\n",
    "            temp.append(binding['itemLabel']['value'])\n",
    "            if binding.get('startyearLabel',None):\n",
    "                temp.append(binding['startyearLabel']['value'])\n",
    "            if binding.get('endyearLabel',None):\n",
    "                temp.append(binding['endyearLabel']['value'])\n",
    "        \n",
    "            if len(temp)>0:\n",
    "                retrieved.append(temp)\n",
    "\n",
    "    if len(retrieved)>0:\n",
    "        return retrieved\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13076/13076 [18:35<00:00, 11.72it/s] \n",
      "100%|██████████| 13076/13076 [19:22<00:00, 11.25it/s] \n",
      "100%|██████████| 13076/13076 [19:44<00:00, 11.04it/s] \n",
      "100%|██████████| 13076/13076 [19:46<00:00, 11.02it/s] \n",
      "100%|██████████| 13076/13076 [21:53<00:00,  9.96it/s] \n",
      "100%|██████████| 13076/13076 [23:14<00:00,  9.38it/s] \n",
      "100%|██████████| 13076/13076 [22:52<00:00,  9.53it/s] \n",
      "100%|██████████| 13076/13076 [22:43<00:00,  9.59it/s] \n"
     ]
    }
   ],
   "source": [
    "gender_series = new_unified_person_df.progress_apply(process_query,axis=1,args=('gender',))\n",
    "religion_series = new_unified_person_df.progress_apply(process_query,axis=1,args=('religion',))\n",
    "educated_series = new_unified_person_df.progress_apply(process_query,axis=1,args=('educated',))\n",
    "occupation_series = new_unified_person_df.progress_apply(process_query,axis=1,args=('occupation',))\n",
    "positionheld_series = new_unified_person_df.progress_apply(process_query,axis=1,args=('positionheld',))\n",
    "citizenship_series = new_unified_person_df.progress_apply(process_query,axis=1,args=('citizenship',))\n",
    "party_series = new_unified_person_df.progress_apply(process_query,axis=1,args=('party',))\n",
    "memberof_series = new_unified_person_df.progress_apply(process_query,axis=1,args=('memberof',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"merged_extra_df = pd.DataFrame.from_dict({'gender':gender_series,\\n                        'religion':religion_series,\\n                        'educated_at':educated_series,\\n                        'occupation':occupation_series,\\n                        'position_held':positionheld_series,\\n                        'citizenship':citizenship_series,\\n                        'member_of':memberof_series,\\n                        'political_party':party_series})\\n\\nmerged_extra_df.to_parquet('tables/person_wikidata_extras.parquet')\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no need to this!\n",
    "'''merged_extra_df = pd.DataFrame.from_dict({'gender':gender_series,\n",
    "                        'religion':religion_series,\n",
    "                        'educated_at':educated_series,\n",
    "                        'occupation':occupation_series,\n",
    "                        'position_held':positionheld_series,\n",
    "                        'citizenship':citizenship_series,\n",
    "                        'member_of':memberof_series,\n",
    "                        'political_party':party_series})\n",
    "\n",
    "merged_extra_df.to_parquet('tables/person_wikidata_extras.parquet')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_unified_person_df['gender'] = list(map(lambda x:x[0][1] if x else None,gender_series))\n",
    "new_unified_person_df.to_parquet('tables/tables_52_88/new_unified_person_df_final.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_series_map = {'religion':religion_series,\n",
    "                    'school':educated_series,\n",
    "                    'occupation':occupation_series,\n",
    "                    'role':positionheld_series,\n",
    "                    'citizenship':citizenship_series,\n",
    "                    'political_party':party_series}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframes of extra information\n",
    "\n",
    "# series with NO start-end year information\n",
    "for series_name in ['religion', 'school', 'occupation']:\n",
    "\n",
    "    series = name_series_map[series_name]\n",
    "\n",
    "    temp_df = pd.concat([new_unified_person_df['name_set'],series],axis=1)\n",
    "    temp_df.rename(columns={0:'info_list'},inplace=True)\n",
    "\n",
    "    info_df = pd.DataFrame(columns=['name_set','info_name','info_tag'])\n",
    "\n",
    "    def aux(row):\n",
    "        global info_df\n",
    "\n",
    "        name_set = row['name_set']\n",
    "        info_list = row['info_list']\n",
    "\n",
    "        if not info_list:\n",
    "            info_df = pd.concat((info_df,pd.DataFrame({'name_set':[name_set],'info_name':[None],'info_tag':[None]})))\n",
    "        else:\n",
    "            for info in info_list:\n",
    "                info_df = pd.concat((info_df,pd.DataFrame({'name_set':[name_set],'info_name':[info[1]],'info_tag':[info[0]]})))\n",
    "        \n",
    "        return\n",
    "\n",
    "    temp_df.apply(lambda x: aux(x),axis=1)\n",
    "\n",
    "    info_df.dropna(thresh=2,inplace=True) # exclude persons with no info\n",
    "    info_df.to_parquet('tables/tables_52_88/person_'+series_name+'.parquet')\n",
    "\n",
    "\n",
    "# series with start-end year information\n",
    "for series_name in ['role', 'citizenship', 'political_party']:\n",
    "\n",
    "    series = name_series_map[series_name]\n",
    "\n",
    "    temp_df = pd.concat([new_unified_person_df['name_set'],series],axis=1)\n",
    "    temp_df.rename(columns={0:'info_list'},inplace=True)\n",
    "\n",
    "    info_df = pd.DataFrame(columns=['name_set','info_name','info_tag','start_year','end_year'])\n",
    "\n",
    "    def aux(row):\n",
    "        global info_df\n",
    "\n",
    "        name_set = row['name_set']\n",
    "        info_list = row['info_list']\n",
    "\n",
    "        if not info_list:\n",
    "            info_df = pd.concat((info_df,pd.DataFrame({'name_set':[name_set],\n",
    "                                                        'info_name':[None],\n",
    "                                                        'info_tag':[None],\n",
    "                                                        'start_year':[None],\n",
    "                                                        'end_year':[None]})))\n",
    "        else:\n",
    "            for info in info_list:\n",
    "                info_df = pd.concat((info_df,pd.DataFrame({'name_set':[name_set],\n",
    "                                                            'info_name':[info[1]],\n",
    "                                                            'info_tag':[info[0]],\n",
    "                                                            'start_year':[info[2] if len(info)>2 else None],\n",
    "                                                            'end_year':[info[3] if len(info)>3 else None]})))\n",
    "        \n",
    "        return\n",
    "\n",
    "    temp_df.apply(lambda x: aux(x),axis=1)\n",
    "\n",
    "    info_df.dropna(thresh=2,inplace=True) # exclude persons with no info\n",
    "    info_df.to_parquet('tables/tables_52_88/person_'+series_name+'.parquet')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adding country information to political party and school (comes with above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_country_tag(Q):\n",
    "\n",
    "    try:\n",
    "        query = \"\"\"\n",
    "        SELECT ?country ?countryLabel\n",
    "        WHERE \n",
    "        {\n",
    "        wd:\"\"\"+Q+\"\"\" wdt:P17 ?country.\n",
    "        SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n",
    "        }\"\"\"\n",
    "        \n",
    "        sparqlwd.setQuery(query)\n",
    "\n",
    "        return sparqlwd.query().convert()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'name: {Q}')\n",
    "        print(f'error message: {e}')\n",
    "        return {'head': {'vars': ['item']}, 'results': {'bindings': []}}\n",
    "\n",
    "\n",
    "def process_entities(entity):\n",
    "\n",
    "    res = get_country_tag(entity.split('/')[-1])\n",
    "    \n",
    "    if len(res['results']['bindings'])==0:\n",
    "        return ''\n",
    "    else: \n",
    "        # not checking multiple countries since meaningless\n",
    "        binding = res['results']['bindings'][0]\n",
    "\n",
    "        return binding['countryLabel']['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_country_info(df):\n",
    "    party_tag_list = pd.unique(df['info_tag'])\n",
    "    country_col = list(map(lambda x: process_entities(x),party_tag_list))\n",
    "    party_tag_country_dict = dict(zip(party_tag_list,country_col))\n",
    "    return df['info_tag'].apply(lambda x: party_tag_country_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_party_df = pd.read_parquet('tables/tables_52_88/person_political_party.parquet')\n",
    "person_party_df['country'] = add_country_info(person_party_df)\n",
    "person_party_df.to_parquet('tables/tables_52_88/person_political_party.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_school_df = pd.read_parquet('tables/tables_52_88/person_school.parquet')\n",
    "person_school_df['country'] = add_country_info(person_school_df)\n",
    "person_school_df.to_parquet('tables/tables_52_88/person_school.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
