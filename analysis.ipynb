{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gokberk/miniconda3/envs/ml4hc_project2/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bertopic import BERTopic\n",
    "import sqlite3\n",
    "import sqllite_handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('tables/texts_69_76.db')\n",
    "cur = conn.cursor()\n",
    "\n",
    "res = cur.execute(\"SELECT TEXT FROM transcript\")\n",
    "fetched = res.fetchall()\n",
    "free_text_list = list(map(lambda x: x[0], fetched))\n",
    "\n",
    "topic_model = BERTopic.load(\"plots/topic_model_69_76\")\n",
    "\n",
    "doc_df = pd.read_csv('tables/doc_69_76.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messy_doc_topic_df = topic_model.get_document_info(free_text_list)\n",
    "\n",
    "topic_desc_df = messy_doc_topic_df[['Name','Top_n_words']].drop_duplicates(ignore_index=True)\n",
    "doc_topic_df = pd.DataFrame({'id_to_text':doc_df['id_to_text'],'assigned_topic':messy_doc_topic_df['Name']})\n",
    "\n",
    "topic_desc_df.to_csv('tables/topic_descp_69_76.csv')\n",
    "doc_topic_df.to_csv('tables/doc_topic_69_76.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### construction below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pyLDAvis.gensim_models as gensimvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "triplet_extractor = pipeline('text2text-generation', model='Babelscape/rebel-large', tokenizer='Babelscape/rebel-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt ='Luis lives in Zurich.'\n",
    "\n",
    "out_ = triplet_extractor(txt, return_tensors=True, return_text=False)[0][\"generated_token_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_text = triplet_extractor.tokenizer.batch_decode(out_['output_ids'][0])\n",
    "\n",
    "extracted_triplets = extract_triplets(extracted_text[0])\n",
    "print(extracted_triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse the generated text and extract the triplets\n",
    "def extract_triplets(text):\n",
    "    triplets = []\n",
    "    relation, subject, relation, object_ = '', '', '', ''\n",
    "    text = text.strip()\n",
    "    current = 'x'\n",
    "    for token in text.replace(\"<s>\", \"\").replace(\"<pad>\", \"\").replace(\"</s>\", \"\").split():\n",
    "        if token == \"<triplet>\":\n",
    "            current = 't'\n",
    "            if relation != '':\n",
    "                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
    "                relation = ''\n",
    "            subject = ''\n",
    "        elif token == \"<subj>\":\n",
    "            current = 's'\n",
    "            if relation != '':\n",
    "                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
    "            object_ = ''\n",
    "        elif token == \"<obj>\":\n",
    "            current = 'o'\n",
    "            relation = ''\n",
    "        else:\n",
    "            if current == 't':\n",
    "                subject += ' ' + token\n",
    "            elif current == 's':\n",
    "                object_ += ' ' + token\n",
    "            elif current == 'o':\n",
    "                relation += ' ' + token\n",
    "    if subject != '' and relation != '' and object_ != '':\n",
    "        triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
    "    return triplets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def remove_persons(txt):\n",
    "    document = nlp(txt)\n",
    "\n",
    "    edited_txt = \"\"\n",
    "    for ent in document:\n",
    "        \n",
    "        if ent.ent_type_=='PERSON':\n",
    "            if ent.whitespace_:\n",
    "                edited_txt += 'Person'+ ' '\n",
    "            else:\n",
    "                edited_txt += 'Person'\n",
    "        else:\n",
    "            if ent.whitespace_:\n",
    "                edited_txt += ent.text+ ' '\n",
    "            else:\n",
    "                edited_txt += ent.text\n",
    "    \n",
    "    return edited_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "doc_df = pd.read_csv('tables/doc_69_76v30.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_list = doc_df['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_txt_list = list(map(lambda x: remove_persons(x), txt_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_txt_list[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keybert import KeyBERT\n",
    "\n",
    "# Extract keywords\n",
    "kw_model = KeyBERT()\n",
    "keywords = kw_model.extract_keywords(txt_list[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"plots/free_text_list\", \"rb\") as fp:\n",
    "        free_text_list = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"Relations between Greece and Turkey began in the 1830s following Greece's formation after its declaration of independence from the Ottoman Empire. Modern relations began when Turkey declared its formation in 1923 following the defeat of the Ottoman Empire in World War I. \\\n",
    "Greece and Turkey have a rivalry with a history of events that have been used to justify their nationalism.[1][2] These events include the population exchange between Greece and Turkey, the Istanbul pogrom and Cypriot intercommunal violence. Greek-Turkish feuding was not a significant factor in international relations from 1930 to 1955, and during the Cold War, domestic and bipolar politics limited competitive behaviour against each other.[3][4] By the mid-1990s and later decades, the restraint on their rivalry was removed, and both nations had become each other's biggest security risk.[5][6]\\\n",
    "Control of the eastern Mediterranean and Aegean seas remain the basis of the countries' rivalry. Following the end of World War II, the UNCLOS treaty, the decolonisation of Cyprus, and the addition of the Dodecanese to Greece's territory have caused turbulence in the relationship. Several issues frequently affect their current relations, including territorial disputes over the sea and air, minority rights, and Turkey's relationship with the European Union (EU) and its member statesâ€”especially Cyprus.[7][8] Control of energy pipelines is also an increasing focus in their relations.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in sentences:\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    print(sentence)\n",
    "    ss = sid.polarity_scores(sentence)\n",
    "    for k in sorted(ss):\n",
    "        print('{0}: {1}, '.format(k, ss[k]), end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def apply_ner(sentence):\n",
    "\n",
    "    doc = nlp(sentence)\n",
    "\n",
    "    named_entities = []\n",
    "\n",
    "    entity_chunk = None #(entity,type)\n",
    "\n",
    "    for token in doc:\n",
    "        if token.ent_iob_ == 'O':\n",
    "            if entity_chunk:\n",
    "                named_entities.append(entity_chunk)\n",
    "                entity_chunk = None\n",
    "        elif token.ent_iob_ == 'B':\n",
    "            if entity_chunk:\n",
    "                named_entities.append(entity_chunk)\n",
    "                entity_chunk = None\n",
    "            entity_chunk = (token.text,token.ent_type_)\n",
    "        else:\n",
    "            entity_chunk_text = entity_chunk[0]\n",
    "            entity_chunk_type = entity_chunk[1]\n",
    "            entity_chunk = (entity_chunk_text+' '+token.text,entity_chunk_type)\n",
    "\n",
    "\n",
    "    uninformative_entities = ['DATE','TIME','QUANTITY','ORDINAL','CARDINAL','QUANTITY','MONEY','PERCENT']\n",
    "\n",
    "    named_entities = list(filter(lambda x: True if x[1] not in uninformative_entities else False, named_entities))\n",
    "    named_entities = np.unique(named_entities,axis=0) \n",
    "\n",
    "    return named_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('tables/texts_69_76.db')\n",
    "cur = conn.cursor()\n",
    "\n",
    "res = cur.execute(\"SELECT TEXT FROM transcript\")\n",
    "fetched = res.fetchall()\n",
    "free_text_list = list(map(lambda x: x[0], fetched))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUBJECT Letter to Prime Minister Papadopoulos As US assistance recipients improve their economic condition, it has been our practice to shift them gradually from grant military assistance to foreign military sales credits. You may recall that Iran took this step shortly after your visit in May last year. Several other countries were considered to make this transition in FY 1974. Greece was one of them. When the Greek government learned of this, they decided to do the same thing that Iran did last springâ€”take themselves off the grant list. They judged that the amount of money had become quite small and that their being on the recipient list subjected them to continued Congressional criticism. They preferred to initiate the termination of grant military assistance. Greece will receive $65 million in military sales credits in FY 1974. Prime Minister Papadopoulos wrote you a letter [Tab B] At Tab A is a suggested reply to the Prime Minister treating this transition in a low key way and expressing appreciation for Greeceâ€™s contribution to NATO.  Recommendation: That you sign the letter to Prime Minister Papadopoulos at Tab A. [Text cleared with Mr. Gergen.] '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "free_text_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Congressional', 'NORP'],\n",
       "       ['Gergen', 'PERSON'],\n",
       "       ['Greece', 'GPE'],\n",
       "       ['Greek', 'NORP'],\n",
       "       ['Iran', 'GPE'],\n",
       "       ['NATO', 'ORG'],\n",
       "       ['Papadopoulos', 'PERSON'],\n",
       "       ['SUBJECT Letter', 'PERSON'],\n",
       "       ['Tab A.', 'PERSON'],\n",
       "       ['US', 'GPE']], dtype='<U14')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply_ner(free_text_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_df = pd.read_parquet('tables/new_unified_person_df_final.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['USA, Commander of the United States Military Assistance Command, Vietnam',\n",
       "       'General, USA, Commander, United States Military Assistance Command, Vietnam',\n",
       "       'Major General, USA, Commander of the United States Military Assistance Command, Vietnam',\n",
       "       'General, USA, Army Chief of Staff until September 4, 1974',\n",
       "       'General, USA; Commander, United States Military Assistance Command, Vietnam (MACV) from July 3, 1968, until June 28, 1972; Army Chief of Staff from October 12, 1972, until September 4, 1974',\n",
       "       'General, USA; Chief of Staff until September 4, 1974',\n",
       "       'General, USA, Commander, United States Military Assistance Command, Vietnam until June 28, 1972; Chief of Staff, USA, from October 12',\n",
       "       'General, USA, Commander, United States Military Assistance Command, Vietnam until June 28, 1972; Chief of Staff, USA, from October 12',\n",
       "       'General, USA; Commander, Military Assistance Command Vietnam until June 28, 1972; Chief of Staff, U.S. Army from October 12, 1972',\n",
       "       'General, USA, Commander, Military Assistance Command Vietnam until June 28, 1972; Chief of Staff, U.S. Army from October 12, 1972',\n",
       "       'USA, Commander, U.S. Military Assistance Command, Vietnam; thereafter, Army Chief of Staff, USA',\n",
       "       'USA, Army Chief of Staff until his death in September 1974',\n",
       "       'USA, Commander, U.S. Military Assistance Command, Vietnam; thereafter, Army Chief of Staff, USA',\n",
       "       'USA, Commander, U.S. Military Assistance Command, Vietnam',\n",
       "       'USA, Chief of Staff, U.S. Army, from October 1972',\n",
       "       'USA, Commander, U.S. Military Assistance Command, Vietnam; Army Chief of Staff from July 1972',\n",
       "       'General, USA; Army Chief of Staff until September 1974',\n",
       "       'General, USA, Commander, U.S. Military Command, Vietnam; Army Chief of Staff from October 12, 1972'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_df['description_list'].iloc[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4hc_project2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "17915d4eccf26051373144ab496c4cfde1d85bab0b3b06c6ac905c8927260055"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
