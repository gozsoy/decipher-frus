{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hack to make the module importable\n",
    "import sys\n",
    "sys.path.append(r'./../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from py2neo import Graph, NodeMatcher\n",
    "import pandas as pd\n",
    "\n",
    "from rel2graph.relational_modules.pandas import PandasDataframeIterator\n",
    "from rel2graph import IteratorIterator\n",
    "from rel2graph import Converter\n",
    "from rel2graph.utils import load_file\n",
    "from rel2graph import register_attribute_postprocessor, Attribute, register_attribute_preprocessor, Resource, register_subgraph_preprocessor\n",
    "import rel2graph.common_modules\n",
    "from rel2graph.common_modules import DATE\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "filename = \"frus_schema.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Logging\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(filename='tables/rel2graphlogs.log',level=logging.WARNING)\n",
    "logger = logging.getLogger(\"rel2graph\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "log_formatter = logging.Formatter(\"%(asctime)s [%(threadName)s]::[%(levelname)s]::%(filename)s: %(message)s\")\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setFormatter(log_formatter)\n",
    "logger.addHandler(console_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up sqlite database.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import sqllite_handler\n",
    "\n",
    "rdb_name = 'tables/texts_69_76.db'\n",
    "\n",
    "# Setup sqlite database for transcript texts\n",
    "# Create table if not exists\n",
    "print(\"Setting up sqlite database.\")\n",
    "conn = sqlite3.connect(rdb_name)\n",
    "\n",
    "conn.execute('''CREATE TABLE IF NOT EXISTS transcript\n",
    "        (ID PRIMARY KEY NOT NULL,\n",
    "        TEXT);''')\n",
    "conn.close()\n",
    "\n",
    "sqllite_handler.init(rdb_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc_df = pd.read_csv('tables/doc_69_76.csv') VALID ONE\n",
    "doc_df = pd.read_csv('tables/doc_69_76v30.csv') # EXPERIMENTAL PURPOSES\n",
    "\n",
    "# change year from type 'float' to 'str(int)' suitable for rel2graph\n",
    "doc_df['year'] = doc_df['year'].apply(lambda x: x if math.isnan(x) else str(int(x)))\n",
    "\n",
    "country_df = pd.read_csv('tables/country_69_76.csv')\n",
    "city_country_df = pd.read_parquet('tables/city_69_76_final.parquet')\n",
    "\n",
    "era_df = pd.read_csv('tables/era.csv')\n",
    "year_df = pd.read_csv('tables/year.csv')\n",
    "\n",
    "person_df = pd.read_parquet('tables/new_unified_person_df_final.parquet')\n",
    "person_sentby_df = pd.read_csv('tables/person_sentby_69_76.csv')\n",
    "person_sentto_df = pd.read_csv('tables/person_sentto_69_76.csv')\n",
    "#person_mentioned_df = pd.read_csv('tables/person_mentioned_single_volume.csv')\n",
    "\n",
    "religion_df = pd.read_parquet('tables/person_religion_69_76.parquet')\n",
    "citizenship_df = pd.read_parquet('tables/person_citizenship_69_76.parquet')\n",
    "occupation_df = pd.read_parquet('tables/person_occupation_69_76.parquet')\n",
    "political_party_df = pd.read_parquet('tables/person_political_party_69_76.parquet')\n",
    "role_df = pd.read_parquet('tables/person_role_69_76.parquet')\n",
    "school_df = pd.read_parquet('tables/person_school_69_76.parquet')\n",
    "\n",
    "redaction_df = pd.read_parquet('tables/redaction_69_76.parquet')\n",
    "topic_desc_df = pd.read_csv('tables/topic_descp_69_76.csv')\n",
    "doc_topic_df = pd.read_csv('tables/doc_topic_69_76.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph = Graph(scheme=\"bolt\", host=\"localhost\", port=7687,  auth=('neo4j', 'bos'), name='neo4j')\n",
    "graph = Graph(scheme=\"bolt\", host=\"localhost\", port=7687,  auth=('neo4j', 'bos'), name='frusphase2')\n",
    "\n",
    "graph.delete_all()  # reset graph (only wehn first creating the databse, here for debugging purposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-22 21:06:05,050 [MainThread]::[DEBUG]::registrar.py: Registered attribute postprocessor 'INT''.\n",
      "2023-02-22 21:06:05,051 [MainThread]::[DEBUG]::registrar.py: Registered attribute postprocessor 'FLOAT''.\n",
      "2023-02-22 21:06:05,053 [MainThread]::[DEBUG]::registrar.py: Registered attribute postprocessor 'AUX''.\n",
      "2023-02-22 21:06:05,054 [MainThread]::[DEBUG]::registrar.py: Registered subgraph preprocessor 'ONLY_CREATE_IF_EXISTS'.\n",
      "2023-02-22 21:06:05,055 [MainThread]::[DEBUG]::registrar.py: Registered attribute preprocessor 'EXPORT_TEXT_TO_DB'.\n"
     ]
    }
   ],
   "source": [
    "# Now neo4j does not support the numpy dtype int64, so we need to convert it to python native int\n",
    "# We create a wrapper for this.\n",
    "@register_attribute_postprocessor\n",
    "def INT(attribute):\n",
    "    # check if field is Nan\n",
    "    if isinstance(attribute.value, float) and math.isnan(attribute.value):\n",
    "        return Attribute(attribute.key, attribute.value)\n",
    "    else:\n",
    "        return Attribute(attribute.key, int(attribute.value))\n",
    "\n",
    "@register_attribute_postprocessor\n",
    "def FLOAT(attribute):\n",
    "    return Attribute(attribute.key, float(attribute.value))\n",
    "\n",
    "@register_attribute_postprocessor\n",
    "def AUX(attribute):\n",
    "    # check if field is Nan\n",
    "    if isinstance(attribute.value, float) and math.isnan(attribute.value):\n",
    "        return Attribute(attribute.key, attribute.value)\n",
    "    else:\n",
    "        return Attribute(attribute.key, datetime.strptime(attribute.value,'%Y-%m-%d'))\n",
    "\n",
    "\n",
    "@register_subgraph_preprocessor\n",
    "def ONLY_CREATE_IF_EXISTS(resource: Resource, key) -> Resource:\n",
    "    val = resource[key]\n",
    "    if isinstance(val, float) and math.isnan(val): # check if NaN\n",
    "        return None\n",
    "    elif not val: # check if None\n",
    "        return None\n",
    "    else:\n",
    "        return resource\n",
    "\n",
    "@register_attribute_preprocessor\n",
    "def EXPORT_TEXT_TO_DB(resource: Resource) -> Resource:\n",
    "    text = resource[\"text\"]\n",
    "    id = resource[\"id_to_text\"]\n",
    "    sqllite_handler.execute(f\"INSERT INTO transcript VALUES(?,?);\", (id,text))\n",
    "    return resource\n",
    "\n",
    "\n",
    "# In the schema file wrap the Person.ID attribute in the INT wrapper\n",
    "#        + ID = INT(Person.ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = IteratorIterator([PandasDataframeIterator(doc_df, \"Document\"), \n",
    "                             PandasDataframeIterator(era_df, \"Era\"), \n",
    "                             PandasDataframeIterator(person_df, \"Person\"),\n",
    "                             PandasDataframeIterator(year_df, \"Year\"),\n",
    "                             #PandasDataframeIterator(person_sentby_df, \"PersonSentBy\"),\n",
    "                             #PandasDataframeIterator(person_sentto_df, \"PersonSentTo\"),\n",
    "                             #PandasDataframeIterator(person_mentioned_df, \"PersonMentionedIn\"),\n",
    "                             PandasDataframeIterator(country_df, \"Country\"),\n",
    "                             PandasDataframeIterator(city_country_df, \"CityCountry\"),\n",
    "                             PandasDataframeIterator(religion_df, \"Religion\"),\n",
    "                             PandasDataframeIterator(occupation_df, \"Occupation\"),\n",
    "                             PandasDataframeIterator(political_party_df, \"PoliticalParty\"),\n",
    "                             PandasDataframeIterator(role_df, \"Role\"),\n",
    "                             PandasDataframeIterator(school_df, \"School\"),\n",
    "                             PandasDataframeIterator(citizenship_df, \"Citizenship\"),\n",
    "                             #PandasDataframeIterator(redaction_df, \"Redaction\"),\n",
    "                             #PandasDataframeIterator(topic_desc_df, \"Topic\"),\n",
    "                             #PandasDataframeIterator(doc_topic_df, \"DocTopic\"),\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = Converter(load_file(filename), iterator, graph, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "converter(progress_bar = tqdm)\n",
    "\n",
    "# Quit sqlite handler\n",
    "sqllite_handler.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiment below delete later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(rdb_name)\n",
    "cur = conn.cursor()\n",
    "res = cur.execute(\"SELECT TEXT FROM transcript WHERE ID='frus1969-76v30_d10'\")\n",
    "res.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = cur.execute(\"SELECT TEXT FROM transcript WHERE ID='frus1969-76v30_d10'\")\n",
    "res.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"plots/free_text_list\", \"rb\") as fp:\n",
    "        free_text_list = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
