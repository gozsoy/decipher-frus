{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import copy \n",
    "import math\n",
    "import itertools\n",
    "import jellyfish\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "ns = {'xml': 'http://www.w3.org/XML/1998/namespace',\n",
    "      'dflt': 'http://www.tei-c.org/ns/1.0',\n",
    "      'frus':'http://history.state.gov/frus/ns/1.0',\n",
    "      'xi':'http://www.w3.org/2001/XInclude'\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_city(doc):\n",
    "\n",
    "    # city\n",
    "    place_tag = doc.find('.//dflt:placeName',ns)\n",
    "    if place_tag is not None:\n",
    "        txt = \"\".join(place_tag.itertext())\n",
    "        city = \" \".join(txt.split())\n",
    "    else:\n",
    "        city = None\n",
    "\n",
    "    global city_df\n",
    "    city_df = pd.concat((city_df, pd.DataFrame({'name':[city]})),ignore_index=True)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "volume_root = 'frus1969-76'\n",
    "\n",
    "city_df = pd.DataFrame(columns=['name'])\n",
    "\n",
    "\n",
    "#for file in glob.glob('volumes/*'):\n",
    "for file in glob.glob('volumes/'+volume_root+'*'):\n",
    "\n",
    "    tree = ET.parse(file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    docs = root.findall('./dflt:text/dflt:body//dflt:div[@type=\"document\"]', ns)\n",
    "    for doc in docs:\n",
    "        extract_city(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_df.dropna(inplace=True)\n",
    "city_df.drop_duplicates(inplace=True)\n",
    "city_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension_col = city_df['name'].apply(lambda x: \" \".join(x.split(',')[1:]))\n",
    "name_col = city_df['name'].apply(lambda x: x.split(',')[0])\n",
    "city_df['name'] = name_col\n",
    "city_df['extension'] = extension_col\n",
    "city_df['extension'] = city_df['extension'].apply(lambda x: None if len(x)==0 else x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wc matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_df = pd.read_csv('world-cities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers\n",
    "def geo_match(pattern,string):\n",
    "    \n",
    "    if pattern !=pattern:\n",
    "        return None\n",
    "    elif re.search(pattern,string):\n",
    "        return pattern\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def f(string):\n",
    "\n",
    "    if not string:\n",
    "        return None\n",
    "    \n",
    "    tl = list(wc_df[wc_df['country'].apply(lambda pattern: True if geo_match(pattern,string) else False)].drop_duplicates(subset='country')['country'].values)\n",
    "    if len(tl)==0:\n",
    "        tl = list(wc_df[wc_df['subcountry'].apply(lambda pattern: True if geo_match(pattern,string) else False)].drop_duplicates(subset='country')['country'].values)\n",
    "\n",
    "    if len(tl)==0:\n",
    "        return None\n",
    "    elif len(tl)==1:\n",
    "        return tl[0]\n",
    "    else:\n",
    "        print(f'multi-match for {string}. Check later!')\n",
    "        return tl\n",
    "\n",
    "def f2(string):\n",
    "\n",
    "    if not string:\n",
    "        return None\n",
    "\n",
    "    tl = list(wc_df[wc_df['subcountry'].apply(lambda pattern: True if geo_match(pattern,string) else False)].drop_duplicates(subset='country')['country'].values)\n",
    "\n",
    "    if len(tl)==0:\n",
    "        return None\n",
    "    elif len(tl)==1:\n",
    "        return tl[0]\n",
    "    else:\n",
    "        print(f'multi-match for {string}. Check later!')\n",
    "        return tl\n",
    "\n",
    "def merger(row):\n",
    "\n",
    "    d1 = row['extension_match']\n",
    "    d2 = row['wc_guess']\n",
    "\n",
    "    if not d1 and d2!=d2:\n",
    "        return None\n",
    "    elif not d1:\n",
    "        return d2\n",
    "    else:\n",
    "        return d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi-match for  Maryland. Check later!\n",
      "multi-match for  Florida. Check later!\n",
      "multi-match for  Maryland. Check later!\n",
      "multi-match for Salzburg White House. Check later!\n",
      "multi-match for Dar es Salaam. Check later!\n",
      "multi-match for Salzburg. Check later!\n",
      "multi-match for La Paz. Check later!\n",
      "multi-match for San JosÃ©. Check later!\n",
      "multi-match for San Salvador. Check later!\n",
      "multi-match for Montevideo. Check later!\n"
     ]
    }
   ],
   "source": [
    "city_df['extension_match'] = city_df['extension'].apply(lambda x:f(x))\n",
    "city_df['wc_guess'] = city_df[city_df['extension'].isna()]['name'].apply(lambda x:f2(x))\n",
    "#city_df['merged']=city_df.apply(lambda x: merger(x),axis=1)\n",
    "city_df['merged']=city_df['extension_match']\n",
    "\n",
    "city_df=city_df[['name','merged','extension_match','wc_guess']]\n",
    "city_df.rename(columns={'merged':'country'},inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resolve multi-match cases by hand before proceeding next part!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and edit\n",
    "city_df.to_csv('tables/city_69_76.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load corrected one\n",
    "city_df = pd.read_csv('tables/city_69_76.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wikidata matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from collections import Counter\n",
    "from dask.diagnostics import ProgressBar\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent = 'CoolBot/0.0 (https://example.org/coolbot/; coolbot@example.org)'\n",
    "\n",
    "sparqlwd = SPARQLWrapper(\"https://query.wikidata.org/sparql\", agent=user_agent)\n",
    "sparqlwd.setReturnFormat(JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_if_capital(name):\n",
    "\n",
    "    try:\n",
    "        query = \"\"\"\n",
    "        SELECT ?country ?countryLabel WHERE {\n",
    "        SERVICE wikibase:mwapi {\n",
    "            bd:serviceParam wikibase:endpoint \"www.wikidata.org\";\n",
    "                            wikibase:api \"EntitySearch\";\n",
    "                            mwapi:search  \\'\"\"\"+name+\"\"\"\\';\n",
    "                            mwapi:language \"en\".\n",
    "            ?city wikibase:apiOutputItem mwapi:item.\n",
    "            ?num wikibase:apiOrdinal true.\n",
    "        }\n",
    "        ?city wdt:P31 wd:Q5119.\n",
    "        ?city wdt:P17 ?country.\n",
    "        SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\".}\n",
    "        }\n",
    "        \"\"\"\n",
    "        \n",
    "        sparqlwd.setQuery(query)\n",
    "\n",
    "        return sparqlwd.query().convert()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'name: {name}')\n",
    "        print(f'error message: {e}')\n",
    "        return {'head': {'vars': ['item']}, 'results': {'bindings': []}}\n",
    "\n",
    "\n",
    "def find_if_bigcity(name):\n",
    "\n",
    "    try:\n",
    "        query = \"\"\"\n",
    "        SELECT ?country ?countryLabel WHERE {\n",
    "        SERVICE wikibase:mwapi {\n",
    "            bd:serviceParam wikibase:endpoint \"www.wikidata.org\";\n",
    "                            wikibase:api \"EntitySearch\";\n",
    "                            mwapi:search  \\'\"\"\"+name+\"\"\"\\';\n",
    "                            mwapi:language \"en\".\n",
    "            ?city wikibase:apiOutputItem mwapi:item.\n",
    "            ?num wikibase:apiOrdinal true.\n",
    "        }\n",
    "        ?city (wdt:P31/wdt:P279*) wd:Q1549591.\n",
    "        ?city wdt:P17 ?country.\n",
    "        SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\".}\n",
    "        }\n",
    "        \"\"\"\n",
    "        \n",
    "        sparqlwd.setQuery(query)\n",
    "\n",
    "        return sparqlwd.query().convert()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'name: {name}')\n",
    "        print(f'error message: {e}')\n",
    "        return {'head': {'vars': ['item']}, 'results': {'bindings': []}}\n",
    "\n",
    "\n",
    "def process_name(row, f):\n",
    "\n",
    "    name = row['name']\n",
    "\n",
    "    res = f(name)\n",
    "\n",
    "    candidates = []\n",
    "    selected_country = None\n",
    "    selected_tag = None\n",
    "\n",
    "    for binding in res['results']['bindings']:\n",
    "        candidates.append(binding['countryLabel']['value'])\n",
    "\n",
    "    if len(candidates)>0:\n",
    "        temp_country = Counter(candidates).most_common(1)[0][0]\n",
    "        temp_tag = None\n",
    "\n",
    "        for binding in res['results']['bindings']:\n",
    "            if binding['countryLabel']['value'] == temp_country:\n",
    "                temp_tag = binding['country']['value']\n",
    "                break\n",
    "        \n",
    "        #selected_country.add(temp_country)\n",
    "        selected_country = temp_country\n",
    "        #wiki_tag.add(temp_tag)\n",
    "        selected_tag = temp_tag\n",
    "\n",
    "    return selected_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find country if city is capital\n",
    "wiki_df = city_df[city_df['extension_match'].apply(lambda x: True if x!=x else False)]\n",
    "city_df['wiki_capital_guess'] = wiki_df.apply(process_name,axis=1,f=find_if_capital)\n",
    "\n",
    "# find country if city is big city but not capital\n",
    "wiki_df = city_df[city_df['extension_match'].apply(lambda x: True if x!=x else False) & city_df['wiki_capital_guess'].apply(lambda x: False if x else True)]\n",
    "city_df['wiki_bigcity_guess'] = wiki_df.apply(process_name,axis=1,f=find_if_bigcity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merger2(row):\n",
    "\n",
    "    d1 = row['wiki_capital_guess']\n",
    "    d2 = row['wiki_bigcity_guess']\n",
    "\n",
    "    if (not d2 or d2!=d2) and (not d1 or d1!=d1):\n",
    "        return None\n",
    "    elif (not d2 or d2!=d2):\n",
    "        return d1\n",
    "    else:\n",
    "        return d2\n",
    "\n",
    "city_df['merged_wiki'] = city_df.apply(merger2,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merger3(row):\n",
    "\n",
    "    d1 = row['country']\n",
    "    d2 = row['merged_wiki']\n",
    "\n",
    "    if not d2 and d1!=d1:\n",
    "        return None\n",
    "    elif d1!=d1:\n",
    "        return d2\n",
    "    else:\n",
    "        return d1\n",
    "\n",
    "city_df['country'] = city_df.apply(merger3,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>extension_match</th>\n",
       "      <th>wc_guess</th>\n",
       "      <th>wiki_capital_guess</th>\n",
       "      <th>wiki_bigcity_guess</th>\n",
       "      <th>merged_wiki</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Salzburg White House</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Austria', 'Cape Verde']</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>Zurich</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>Crimea</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ukraine</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>Kabul</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>102</td>\n",
       "      <td>Miesbach</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Japan</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>103</td>\n",
       "      <td>Martinique</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Martinique</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>104</td>\n",
       "      <td>Conakry</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Guinea</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>132</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>200</td>\n",
       "      <td>Bali</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>221</td>\n",
       "      <td>Belize City</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Belize</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                  name country extension_match  \\\n",
       "4             4  Salzburg White House    None             NaN   \n",
       "27           27                Zurich    None             NaN   \n",
       "42           42                Crimea    None             NaN   \n",
       "65           65                 Kabul    None             NaN   \n",
       "102         102              Miesbach    None             NaN   \n",
       "103         103            Martinique    None             NaN   \n",
       "104         104               Conakry    None             NaN   \n",
       "132         132                Hawaii    None             NaN   \n",
       "200         200                  Bali    None             NaN   \n",
       "221         221           Belize City    None             NaN   \n",
       "\n",
       "                      wc_guess wiki_capital_guess wiki_bigcity_guess  \\\n",
       "4    ['Austria', 'Cape Verde']               None               None   \n",
       "27                 Switzerland               None               None   \n",
       "42                     Ukraine               None               None   \n",
       "65                 Afghanistan               None               None   \n",
       "102                      Japan               None               None   \n",
       "103                 Martinique               None               None   \n",
       "104                     Guinea               None               None   \n",
       "132              United States               None               None   \n",
       "200                  Indonesia               None               None   \n",
       "221                     Belize               None               None   \n",
       "\n",
       "    merged_wiki  \n",
       "4          None  \n",
       "27         None  \n",
       "42         None  \n",
       "65         None  \n",
       "102        None  \n",
       "103        None  \n",
       "104        None  \n",
       "132        None  \n",
       "200        None  \n",
       "221        None  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for observation only\n",
    "city_df[city_df['country'].apply(lambda x: False if x else True) & city_df['wc_guess'].apply(lambda x: True if x==x else False)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resolve multi-match cases by hand before proceeding next part!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and edit\n",
    "city_df.to_csv('tables/city_69_76.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load corrected one\n",
    "city_df = pd.read_csv('tables/city_69_76.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## misspelling matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_names = city_df['name'].values\n",
    "\n",
    "def compute_sim(s1,func,s2):\n",
    "    return func(s1,s2)\n",
    "\n",
    "def find_matches(s2):\n",
    "\n",
    "    spiro_dist_df = pd.DataFrame({'name_set':all_names,\n",
    "                                'dam_lev_dist':[compute_sim(x, jellyfish.damerau_levenshtein_distance,s2) for x in all_names]})\n",
    "    \n",
    "    misspelling_idx = set(spiro_dist_df[(spiro_dist_df['dam_lev_dist'] <=1)].index.values)\n",
    "\n",
    "    return misspelling_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = {}\n",
    "for idx in tqdm(range(len(all_names))):\n",
    "    name = all_names[idx]\n",
    "    t[idx]=find_matches(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scratch_t = copy.deepcopy(t)\n",
    "changed_flag = True\n",
    "\n",
    "while changed_flag:\n",
    "\n",
    "    changed_flag = False\n",
    "\n",
    "    for key in t:\n",
    "        \n",
    "        for matched_idx in t[key]:\n",
    "\n",
    "            if key != matched_idx:\n",
    "                if scratch_t.get(key, None) and scratch_t.get(matched_idx, None):\n",
    "                    changed_flag = True\n",
    "                    t[key] = t[key].union(t[matched_idx])\n",
    "                    scratch_t.pop(matched_idx, None)\n",
    "        \n",
    "    unwanted = set(t.keys()) - set(scratch_t.keys())\n",
    "    print(f'removing {len(unwanted)} keys.')\n",
    "    for unwanted_key in unwanted: del t[unwanted_key]\n",
    "    scratch_t = copy.deepcopy(t)\n",
    "    print('---')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for temp_key in t:\n",
    "    \n",
    "    te_df = city_df.iloc[list(t[temp_key])]\n",
    "\n",
    "    name_list = te_df['name'].values\n",
    "\n",
    "    country_list = te_df['country'].values\n",
    "    country_list = [c for c in country_list if c==c]\n",
    "    country_list = list(set(country_list))\n",
    "    if len(country_list)==0:\n",
    "        country_list = None\n",
    "    elif len(country_list)==1:\n",
    "        country_list = country_list[0]\n",
    "\n",
    "    city_df.at[temp_key, 'name_list'] = name_list\n",
    "    city_df.at[temp_key, 'country'] = country_list\n",
    "\n",
    "city_df = city_df.loc[t.keys()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
