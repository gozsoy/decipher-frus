{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gokberk/miniconda3/envs/ml4hc_project2/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/gokberk/miniconda3/envs/ml4hc_project2/lib/python3.9/site-packages/spacy/util.py:877: UserWarning: [W095] Model 'en_core_web_sm' (3.2.0) was trained with spaCy v3.2 and may not be 100% compatible with the current version (3.5.0). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import math\n",
    "import pickle\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from graphdatascience import GraphDataScience\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_ner(sentence):\n",
    "\n",
    "    doc = nlp(sentence)\n",
    "\n",
    "    named_entities = []\n",
    "\n",
    "    entity_chunk = None #(entity,type)\n",
    "\n",
    "    for token in doc:\n",
    "        if token.ent_iob_ == 'O':\n",
    "            if entity_chunk:\n",
    "                named_entities.append(entity_chunk)\n",
    "                entity_chunk = None\n",
    "        elif token.ent_iob_ == 'B':\n",
    "            if entity_chunk:\n",
    "                named_entities.append(entity_chunk)\n",
    "                entity_chunk = None\n",
    "            entity_chunk = (token.text,token.ent_type_)\n",
    "        else:\n",
    "            entity_chunk_text = entity_chunk[0]\n",
    "            entity_chunk_type = entity_chunk[1]\n",
    "            entity_chunk = (entity_chunk_text+' '+token.text,entity_chunk_type)\n",
    "\n",
    "\n",
    "    uninformative_entities = ['DATE','TIME','QUANTITY','ORDINAL','CARDINAL','QUANTITY','MONEY','PERCENT','PERSON']\n",
    "\n",
    "    named_entities = list(filter(lambda x: True if x[1] not in uninformative_entities else False, named_entities))\n",
    "    named_entities = np.unique(named_entities,axis=0) \n",
    "\n",
    "    return named_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_df = pd.read_csv('tables/tables_69_76/doc_69_76.csv')\n",
    "doc_df = doc_df[doc_df['subtype']!='editorial-note'] # removing editorial notes\n",
    "\n",
    "id_to_text_list = doc_df['id_to_text'].values\n",
    "free_text_list = doc_df['text'].values\n",
    "year_list = list(map(lambda x: str(int(x)),doc_df['year'].values))\n",
    "era_list = doc_df['era'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner dict computed and saved.\n"
     ]
    }
   ],
   "source": [
    "name_extension = '_69_76_2yearbinned'\n",
    "\n",
    "if os.path.isfile('ne2vec/ner_dict'+name_extension):\n",
    "    with open(\"ne2vec/ner_dict\"+name_extension, \"rb\") as fp:\n",
    "        ner_dict = pickle.load(fp)\n",
    "    print('ner dict loaded.')\n",
    "\n",
    "else:\n",
    "    ner_dict = {}\n",
    "\n",
    "    for idx,text in enumerate(free_text_list):\n",
    "\n",
    "        if not(isinstance(text, float) and math.isnan(text)): # check if NaN\n",
    "            id_to_text = id_to_text_list[idx]\n",
    "            year = year_list[idx]\n",
    "            era = era_list[idx]\n",
    "            ne_list = apply_ner(text)\n",
    "\n",
    "            for ne_tuple in ne_list:\n",
    "                ne = ne_tuple[0]\n",
    "\n",
    "                if not ner_dict.get(ne,None):\n",
    "                    ner_dict[ne] = [(id_to_text,year,era)]\n",
    "                else:\n",
    "                    ner_dict[ne].append((id_to_text,year,era))\n",
    "    \n",
    "    with open('ne2vec/ner_dict'+name_extension, 'wb') as f:\n",
    "        pickle.dump(ner_dict, f)\n",
    "    print('ner dict computed and saved.')\n",
    "\n",
    "\n",
    "min_ne_count = 20 # 50 in original\n",
    "copy_ner_dict = copy.deepcopy(ner_dict)\n",
    "\n",
    "for key in copy_ner_dict:\n",
    "    \n",
    "    if len(ner_dict[key]) < min_ne_count:\n",
    "        del ner_dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ne2doc_df = pd.DataFrame(columns=['id_to_text','named_entity','year','era'])\n",
    "\n",
    "for key in ner_dict:\n",
    "\n",
    "    tuple_list = ner_dict[key]\n",
    "\n",
    "    for tuple in tuple_list:\n",
    "        id, year, era = tuple[0], tuple[1], tuple[2]\n",
    "\n",
    "        ne2doc_df = pd.concat((ne2doc_df, \n",
    "                                pd.DataFrame({'id_to_text':[id],'named_entity':[key],'year':[year],'era':[era]})),\n",
    "                                ignore_index=True)\n",
    "\n",
    "ne2doc_df['year'] = ne2doc_df['year'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x year bins\n",
    "bins = list(range(1960,1981,2))\n",
    "\n",
    "labels = []\n",
    "for i in range(1,len(bins)):\n",
    "    labels.append(str(bins[i-1])[-2:]+'-'+str(bins[i])[-2:])\n",
    "\n",
    "ne2doc_df['bin'] = pd.cut(ne2doc_df['year'], bins=bins, labels=labels, right=True)\n",
    "\n",
    "ne2doc_df['dynamic_named_entity'] = ne2doc_df['named_entity'].astype(str) + ' ' + ne2doc_df['bin'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Turkey 74-76    196\n",
       "Turkey 68-70    185\n",
       "Turkey 72-74    185\n",
       "Turkey 70-72    175\n",
       "Turkey 78-80      8\n",
       "Turkey 76-78      3\n",
       "Name: dynamic_named_entity, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ne2doc_df[ne2doc_df['named_entity']=='Turkey']['dynamic_named_entity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ne2doc_df.to_parquet('ne2vec/ne2doc_df'+name_extension+'.parquet')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### now:\n",
    "##### 1- execute python3 ne_conversion.py\n",
    "##### 2- run cypher commands in \"ne2vec/cypher_commands.txt\" on database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gds = GraphDataScience(\"bolt://localhost:7687\", auth=('neo4j', 'bos'), database='entity2vec18mar')\n",
    "\n",
    "embedding_df = gds.run_cypher(\n",
    "    \"\"\"\n",
    "        match (e:Entity)\n",
    "        return e.name as entity, e['fastrp-embedding'] as fastrp_embedding\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gokberk/miniconda3/envs/ml4hc_project2/lib/python3.9/site-packages/sklearn/manifold/_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/gokberk/miniconda3/envs/ml4hc_project2/lib/python3.9/site-packages/sklearn/manifold/_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "reduced_emb_mat = TSNE(n_components=2, perplexity=50).fit_transform(np.stack(embedding_df['fastrp_embedding']))\n",
    "\n",
    "x,y = reduced_emb_mat[:,0],reduced_emb_mat[:,1]\n",
    "\n",
    "fig = px.scatter(x=x, y=y, text=embedding_df['entity'].values, width=900, height=900)\n",
    "fig.write_html(\"ne2vec/69_76_dynamic_mincnt20_fastrp128.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cossim_mat = cosine_similarity(np.stack(embedding_df['fastrp_embedding']))\n",
    "\n",
    "def most_similar(word, top_n):\n",
    "\n",
    "    word_idx = embedding_df[embedding_df['entity']==word].index[0]\n",
    "\n",
    "    similar_entity_idx = np.argsort(cossim_mat[word_idx])[::-1][1:top_n+1]\n",
    "\n",
    "    similar_entity_names = embedding_df['entity'].values[similar_entity_idx]\n",
    "    similar_entity_sims = cossim_mat[word_idx][similar_entity_idx]\n",
    "\n",
    "    return np.array([similar_entity_names,similar_entity_sims]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Ecevit 74-76', 0.9993930953681697],\n",
       "       ['Caramanlis 74-76', 0.999386941191969],\n",
       "       ['Bitsios 74-76', 0.999161144287318],\n",
       "       ['Aegean 74-76', 0.9985918268278424],\n",
       "       ['the Greek Government 74-76', 0.9984054825012745],\n",
       "       ['Nicosia 74-76', 0.9982051251928411],\n",
       "       ['Famagusta 74-76', 0.9980222253797764],\n",
       "       ['Esenbel 74-76', 0.9978805230426075],\n",
       "       ['Greek - Turkish 74-76', 0.9978783952754865],\n",
       "       ['Clerides 74-76', 0.9976393110088014]], dtype=object)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar('DEMIREL 74-76',10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4hc_project2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "17915d4eccf26051373144ab496c4cfde1d85bab0b3b06c6ac905c8927260055"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
