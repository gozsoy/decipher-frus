{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import copy \n",
    "import math\n",
    "import itertools\n",
    "import jellyfish\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "ns = {'xml': 'http://www.w3.org/XML/1998/namespace',\n",
    "      'dflt': 'http://www.tei-c.org/ns/1.0',\n",
    "      'frus':'http://history.state.gov/frus/ns/1.0',\n",
    "      'xi':'http://www.w3.org/2001/XInclude'\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_person(item, file):\n",
    "    volume = file[8:-4]\n",
    "\n",
    "    persName_item = item.find('.//dflt:persName[@xml:id]', ns)\n",
    "\n",
    "    if persName_item is not None:\n",
    "\n",
    "        persName_text = \"\".join(persName_item.itertext())\n",
    "        person_id = persName_item.attrib['{http://www.w3.org/XML/1998/namespace}id']\n",
    "\n",
    "        all_text = \"\".join(item.itertext())\n",
    "        end_idx = all_text.find(persName_text) + len(persName_text+',')\n",
    "        person_descp = \" \".join(all_text[end_idx:].split())\n",
    "\n",
    "        person_name = \" \".join(re.sub(',','',\" \".join(persName_text.split(', ')[::-1])).split())\n",
    "\n",
    "        person_id = volume + '_' + person_id\n",
    "\n",
    "        global person_df\n",
    "        person_df = pd.concat((person_df, pd.DataFrame({'id':[person_id],\n",
    "                                                    'name':[person_name],\n",
    "                                                    'description':[person_descp]})),ignore_index=True)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volumes/frus1969-76v14.xml\n",
      "---\n",
      "volumes/frus1969-76v28.xml\n",
      "---\n",
      "volumes/frus1969-76v29.xml\n",
      "---\n",
      "volumes/frus1969-76v15.xml\n",
      "---\n",
      "volumes/frus1969-76v01.xml\n",
      "---\n",
      "volumes/frus1969-76v38p1.xml\n",
      "---\n",
      "volumes/frus1969-76v17.xml\n",
      "---\n",
      "volumes/frus1969-76v03.xml\n",
      "---\n",
      "volumes/frus1969-76v02.xml\n",
      "---\n",
      "volumes/frus1969-76v16.xml\n",
      "---\n",
      "volumes/frus1969-76v38p2.xml\n",
      "---\n",
      "volumes/frus1969-76ve15p2Ed2.xml\n",
      "---\n",
      "volumes/frus1969-76v12.xml\n",
      "---\n",
      "volumes/frus1969-76v06.xml\n",
      "---\n",
      "volumes/frus1969-76v07.xml\n",
      "---\n",
      "volumes/frus1969-76v13.xml\n",
      "---\n",
      "volumes/frus1969-76v39.xml\n",
      "---\n",
      "volumes/frus1969-76v05.xml\n",
      "---\n",
      "volumes/frus1969-76v11.xml\n",
      "---\n",
      "volumes/frus1969-76v10.xml\n",
      "---\n",
      "volumes/frus1969-76v04.xml\n",
      "---\n",
      "volumes/frus1969-76ve05p2.xml\n",
      "---\n",
      "volumes/frus1969-76v19p1.xml\n",
      "---\n",
      "volumes/frus1969-76ve05p1.xml\n",
      "---\n",
      "volumes/frus1969-76v19p2.xml\n",
      "---\n",
      "volumes/frus1969-76ve08.xml\n",
      "---\n",
      "volumes/frus1969-76ve09p1.xml\n",
      "---\n",
      "volumes/frus1969-76v42.xml\n",
      "---\n",
      "volumes/frus1969-76ve04.xml\n",
      "---\n",
      "volumes/frus1969-76ve10.xml\n",
      "---\n",
      "volumes/frus1969-76ve06.xml\n",
      "---\n",
      "volumes/frus1969-76ve12.xml\n",
      "---\n",
      "volumes/frus1969-76ve09p2.xml\n",
      "---\n",
      "volumes/frus1969-76v41.xml\n",
      "---\n",
      "volumes/frus1969-76v40.xml\n",
      "---\n",
      "volumes/frus1969-76ve13.xml\n",
      "---\n",
      "volumes/frus1969-76ve07.xml\n",
      "---\n",
      "volumes/frus1969-76ve03.xml\n",
      "---\n",
      "volumes/frus1969-76ve14p2.xml\n",
      "---\n",
      "volumes/frus1969-76ve16.xml\n",
      "---\n",
      "volumes/frus1969-76ve02.xml\n",
      "---\n",
      "volumes/frus1969-76ve14p1.xml\n",
      "---\n",
      "volumes/frus1969-76ve01.xml\n",
      "---\n",
      "volumes/frus1969-76v21.xml\n",
      "---\n",
      "volumes/frus1969-76v35.xml\n",
      "---\n",
      "volumes/frus1969-76v09.xml\n",
      "---\n",
      "volumes/frus1969-76v08.xml\n",
      "---\n",
      "volumes/frus1969-76v34.xml\n",
      "---\n",
      "volumes/frus1969-76v20.xml\n",
      "---\n",
      "volumes/frus1969-76ve11p2.xml\n",
      "---\n",
      "volumes/frus1969-76v36.xml\n",
      "---\n",
      "volumes/frus1969-76v22.xml\n",
      "---\n",
      "volumes/frus1969-76v23.xml\n",
      "---\n",
      "volumes/frus1969-76v37.xml\n",
      "---\n",
      "volumes/frus1969-76ve11p1.xml\n",
      "---\n",
      "volumes/frus1969-76ve15p1.xml\n",
      "---\n",
      "volumes/frus1969-76v33.xml\n",
      "---\n",
      "volumes/frus1969-76v27.xml\n",
      "---\n",
      "volumes/frus1969-76v26.xml\n",
      "---\n",
      "volumes/frus1969-76v32.xml\n",
      "---\n",
      "volumes/frus1969-76ve15p2.xml\n",
      "---\n",
      "volumes/frus1969-76v18.xml\n",
      "---\n",
      "volumes/frus1969-76v24.xml\n",
      "---\n",
      "volumes/frus1969-76v30.xml\n",
      "---\n",
      "volumes/frus1969-76v31.xml\n",
      "---\n",
      "volumes/frus1969-76v25.xml\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "volume_root = 'frus1969-76'\n",
    "\n",
    "person_df = pd.DataFrame(columns=['id','name','description'])\n",
    "\n",
    "\n",
    "for file in glob.glob('volumes/'+volume_root+'*'):\n",
    "#for file in glob.glob('volumes/frus1969-76v30.xml'):\n",
    "\n",
    "    tree = ET.parse(file)\n",
    "    root = tree.getroot()\n",
    "    persons_section = root.find(\"./dflt:text/dflt:front//dflt:div[@xml:id='persons']\", ns)\n",
    "    print(file)\n",
    "    for item in persons_section.findall('.//dflt:item/dflt:hi/dflt:persName[@xml:id]/../..', ns):\n",
    "        extract_person(item,file)\n",
    "    for item in persons_section.findall('.//dflt:item/dflt:persName[@xml:id]/..', ns):\n",
    "        extract_person(item,file)\n",
    "    print('---')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step 1: reduce exactly matched names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unified_person_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aux(row):\n",
    "    global unified_person_dict\n",
    "\n",
    "    if row['name'] in unified_person_dict:\n",
    "      \n",
    "      temp_dict = unified_person_dict[row['name']]\n",
    "\n",
    "      temp_dict['id_list'].append(row['id'])\n",
    "      temp_dict['description_list'].append(row['description'])\n",
    "    \n",
    "    else:\n",
    "      unified_person_dict[row['name']]= {'id_list':[row['id']],\n",
    "                                        'description_list':[row['description']]}\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        None\n",
       "1        None\n",
       "2        None\n",
       "3        None\n",
       "4        None\n",
       "         ... \n",
       "14035    None\n",
       "14036    None\n",
       "14037    None\n",
       "14038    None\n",
       "14039    None\n",
       "Length: 14040, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_df.apply(lambda x:aux(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unified_person_df = pd.DataFrame.from_dict(unified_person_dict,orient='index').reset_index(drop=False)\n",
    "unified_person_df.rename(columns={'index':'name'}, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step 2: reduce names with exactly same words but different combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "unified_person_df['name_set'] = unified_person_df.name.apply(lambda x: \" \".join(sorted(x.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_unified_person_dict = {}\n",
    "\n",
    "def aux2(row):\n",
    "    global new_unified_person_dict\n",
    "\n",
    "    if row['name_set'] in new_unified_person_dict:\n",
    "      \n",
    "        temp_dict = new_unified_person_dict[row['name_set']]\n",
    "\n",
    "        temp_dict['name_list'].append(row['name'])\n",
    "        temp_dict['id_list'] += row['id_list']\n",
    "        temp_dict['description_list'] += row['description_list']\n",
    "    \n",
    "    else:\n",
    "        new_unified_person_dict[row['name_set']]= {'name_list':[row['name']],\n",
    "                                                    'id_list':row['id_list'],\n",
    "                                                    'description_list':row['description_list']}\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "unified_person_df.apply(lambda x:aux2(x), axis=1)\n",
    "\n",
    "new_unified_person_df = pd.DataFrame.from_dict(new_unified_person_dict,orient='index').reset_index(drop=False)\n",
    "new_unified_person_df.rename(columns={'index':'name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>name_list</th>\n",
       "      <th>id_list</th>\n",
       "      <th>description_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bui Diem</td>\n",
       "      <td>[Bui Diem, Diem Bui]</td>\n",
       "      <td>[frus1969-76v14_p_BD5, frus1969-76v06_p_BD1, f...</td>\n",
       "      <td>[South Vietnamese Ambassador to the United Sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Bunker Ellsworth</td>\n",
       "      <td>[Ellsworth Bunker, Bunker Ellsworth]</td>\n",
       "      <td>[frus1969-76v14_p_BE6, frus1969-76v38p2_p_BE_2...</td>\n",
       "      <td>[Ambassador to South Vietnam, Ambassador to th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Castro Fidel Ruz</td>\n",
       "      <td>[Fidel Castro Ruz, Castro Ruz Fidel]</td>\n",
       "      <td>[frus1969-76v14_p_CRF1, frus1969-76v38p1_p_CRF...</td>\n",
       "      <td>[Premier of Cuba, Premier of Cuba, Premier of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Chancellor John</td>\n",
       "      <td>[John Chancellor, Chancellor John]</td>\n",
       "      <td>[frus1969-76v14_p_CJ8, frus1969-76v13_p_CJ1]</td>\n",
       "      <td>[anchor on the NBC Nightly News, anchor on NBC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>B. Connally John Jr.</td>\n",
       "      <td>[Jr. John B. Connally, John B. Jr. Connally]</td>\n",
       "      <td>[frus1969-76v14_p_CJBJ1, frus1969-76v28_p_CJB_...</td>\n",
       "      <td>[Secretary of the Treasury until May 16, 1972,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5393</th>\n",
       "      <td>Wendell Wyatt</td>\n",
       "      <td>[Wendell Wyatt, Wyatt Wendell]</td>\n",
       "      <td>[frus1969-76v37_p_WW_1, frus1969-76v27_p_WW_1]</td>\n",
       "      <td>[member, U.S. House of Representatives (R–Oreg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5588</th>\n",
       "      <td>(Korniyenko) Georgi Kornienko M.</td>\n",
       "      <td>[Kornienko (Korniyenko) Georgi M., Georgi M. K...</td>\n",
       "      <td>[frus1969-76v33_p_KGM_1, frus1969-76v32_p_KGM1]</td>\n",
       "      <td>[Director, United States of America Department...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5599</th>\n",
       "      <td>Aleksandr Shchukin</td>\n",
       "      <td>[Shchukin Aleksandr, Aleksandr Shchukin]</td>\n",
       "      <td>[frus1969-76v33_p_SA_1, frus1969-76v32_p_SA1]</td>\n",
       "      <td>[member of the Soviet SALT Delegation, Soviet ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5655</th>\n",
       "      <td>Niehuss Rosemary</td>\n",
       "      <td>[Niehuss Rosemary, Rosemary Niehuss]</td>\n",
       "      <td>[frus1969-76v27_p_NR_1, frus1969-76v30_p_NR5]</td>\n",
       "      <td>[member, National Security Council Staff, Memb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5681</th>\n",
       "      <td>Bitsios Dimitrios</td>\n",
       "      <td>[Bitsios Dimitrios, Dimitrios Bitsios]</td>\n",
       "      <td>[frus1969-76v26_p_BD_1, frus1969-76v30_p_BD6]</td>\n",
       "      <td>[Greek Foreign Minister from October 1974, Gre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>440 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  name  \\\n",
       "13                            Bui Diem   \n",
       "14                    Bunker Ellsworth   \n",
       "18                    Castro Fidel Ruz   \n",
       "19                     Chancellor John   \n",
       "23                B. Connally John Jr.   \n",
       "...                                ...   \n",
       "5393                     Wendell Wyatt   \n",
       "5588  (Korniyenko) Georgi Kornienko M.   \n",
       "5599                Aleksandr Shchukin   \n",
       "5655                  Niehuss Rosemary   \n",
       "5681                 Bitsios Dimitrios   \n",
       "\n",
       "                                              name_list  \\\n",
       "13                                 [Bui Diem, Diem Bui]   \n",
       "14                 [Ellsworth Bunker, Bunker Ellsworth]   \n",
       "18                 [Fidel Castro Ruz, Castro Ruz Fidel]   \n",
       "19                   [John Chancellor, Chancellor John]   \n",
       "23         [Jr. John B. Connally, John B. Jr. Connally]   \n",
       "...                                                 ...   \n",
       "5393                     [Wendell Wyatt, Wyatt Wendell]   \n",
       "5588  [Kornienko (Korniyenko) Georgi M., Georgi M. K...   \n",
       "5599           [Shchukin Aleksandr, Aleksandr Shchukin]   \n",
       "5655               [Niehuss Rosemary, Rosemary Niehuss]   \n",
       "5681             [Bitsios Dimitrios, Dimitrios Bitsios]   \n",
       "\n",
       "                                                id_list  \\\n",
       "13    [frus1969-76v14_p_BD5, frus1969-76v06_p_BD1, f...   \n",
       "14    [frus1969-76v14_p_BE6, frus1969-76v38p2_p_BE_2...   \n",
       "18    [frus1969-76v14_p_CRF1, frus1969-76v38p1_p_CRF...   \n",
       "19         [frus1969-76v14_p_CJ8, frus1969-76v13_p_CJ1]   \n",
       "23    [frus1969-76v14_p_CJBJ1, frus1969-76v28_p_CJB_...   \n",
       "...                                                 ...   \n",
       "5393     [frus1969-76v37_p_WW_1, frus1969-76v27_p_WW_1]   \n",
       "5588    [frus1969-76v33_p_KGM_1, frus1969-76v32_p_KGM1]   \n",
       "5599      [frus1969-76v33_p_SA_1, frus1969-76v32_p_SA1]   \n",
       "5655      [frus1969-76v27_p_NR_1, frus1969-76v30_p_NR5]   \n",
       "5681      [frus1969-76v26_p_BD_1, frus1969-76v30_p_BD6]   \n",
       "\n",
       "                                       description_list  \n",
       "13    [South Vietnamese Ambassador to the United Sta...  \n",
       "14    [Ambassador to South Vietnam, Ambassador to th...  \n",
       "18    [Premier of Cuba, Premier of Cuba, Premier of ...  \n",
       "19    [anchor on the NBC Nightly News, anchor on NBC...  \n",
       "23    [Secretary of the Treasury until May 16, 1972,...  \n",
       "...                                                 ...  \n",
       "5393  [member, U.S. House of Representatives (R–Oreg...  \n",
       "5588  [Director, United States of America Department...  \n",
       "5599  [member of the Soviet SALT Delegation, Soviet ...  \n",
       "5655  [member, National Security Council Staff, Memb...  \n",
       "5681  [Greek Foreign Minister from October 1974, Gre...  \n",
       "\n",
       "[440 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_unified_person_df[new_unified_person_df['name_list'].apply(lambda x: len(x)==2)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step 3: find and reduce near-duplicate names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step one: (match len>=2 and each word len>=3)\n",
    "# step two: for remaning unmatched, allow edit distance of 1 or 2 for misspellings\n",
    "\n",
    "# caution!!!\n",
    "# Eliot Jr. L. Theodore, and D. Dwight Eisenhower\n",
    "# Georges Guay R. vs George Guay R.\n",
    "# Abrams Creighton General Major W.\n",
    "# Aharon General Major Yariv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gokberk/miniconda3/envs/ml4hc_project2/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_names = new_unified_person_df['name'].values\n",
    "\n",
    "def compute_sim(s1,func,s2):\n",
    "    return func(s1,s2)\n",
    "\n",
    "def compute_exact_word_overlap(s1,s2):\n",
    "    l1 = set([x for x in list(set(tokenizer.tokenize(s1))) if len(x)>=3])\n",
    "    l2 = set([x for x in list(set(tokenizer.tokenize(s2))) if len(x)>=3])\n",
    "\n",
    "    return len(l1.intersection(l2))\n",
    "\n",
    "def find_matches(s2):\n",
    "\n",
    "    spiro_dist_df = pd.DataFrame({'name':all_names,\n",
    "                                'overlap_cnt':[compute_exact_word_overlap(x,s2) for x in all_names],\n",
    "                                'dam_lev_dist':[compute_sim(x, jellyfish.damerau_levenshtein_distance,s2) for x in all_names],\n",
    "                                'jaro_sim':[compute_sim(x, jellyfish.jaro_winkler_similarity,s2) for x in all_names]})\n",
    "    \n",
    "    spiro_dist_df = spiro_dist_df[spiro_dist_df['overlap_cnt']>=2]\n",
    "    match_idx = set(spiro_dist_df[(spiro_dist_df['jaro_sim'] >= 0.9) | (spiro_dist_df['dam_lev_dist'] <=5)].index.values)\n",
    "\n",
    "    return match_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6042/6042 [04:52<00:00, 20.63it/s]\n"
     ]
    }
   ],
   "source": [
    "t = {}\n",
    "for idx in tqdm(range(len(all_names))):\n",
    "    name = all_names[idx]\n",
    "    t[idx]=find_matches(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing 1047 keys.\n",
      "---\n",
      "removing 90 keys.\n",
      "---\n",
      "removing 0 keys.\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "scratch_t = copy.deepcopy(t)\n",
    "changed_flag = True\n",
    "\n",
    "while changed_flag:\n",
    "\n",
    "    changed_flag = False\n",
    "\n",
    "    for key in t:\n",
    "        \n",
    "        for matched_idx in t[key]:\n",
    "\n",
    "            if key != matched_idx:\n",
    "                if scratch_t.get(key, None) and scratch_t.get(matched_idx, None):\n",
    "                    changed_flag = True\n",
    "                    t[key] = t[key].union(t[matched_idx])\n",
    "                    scratch_t.pop(matched_idx, None)\n",
    "        \n",
    "    unwanted = set(t.keys()) - set(scratch_t.keys())\n",
    "    print(f'removing {len(unwanted)} keys.')\n",
    "    for unwanted_key in unwanted: del t[unwanted_key]\n",
    "    scratch_t = copy.deepcopy(t)\n",
    "    print('---')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for temp_key in t:\n",
    "    \n",
    "    te_df = new_unified_person_df.iloc[list(t[temp_key])]\n",
    "\n",
    "    name_list = list(itertools.chain.from_iterable(te_df['name_list'].values))\n",
    "    id_list = list(itertools.chain.from_iterable(te_df['id_list'].values))\n",
    "    description_list = list(itertools.chain.from_iterable(te_df['description_list'].values))\n",
    "\n",
    "    new_unified_person_df.at[temp_key, 'name_list'] = name_list\n",
    "    new_unified_person_df.at[temp_key, 'id_list'] = id_list\n",
    "    new_unified_person_df.at[temp_key, 'description_list'] = description_list\n",
    "\n",
    "new_unified_person_df = new_unified_person_df.loc[t.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_unified_person_df.sample(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4hc_project2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "17915d4eccf26051373144ab496c4cfde1d85bab0b3b06c6ac905c8927260055"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
