15 march (while colab experiments running)
DONE- dynamic ne2vec (skeleton code)
increase KG (nb -> py)
readings & brainstorming hugely: spread info, avoid document dominance

16 march
add ne and their sentiment to KG -only using sentiments for ne that will be used in ne2vec?-
mix dynamic embeddings with topic modeling  (skeleton code)  

obtain instutions from frus -do it before meeting-


some results about ultimate goals before historian meeting
creative day full of analysis


mechanics: nb -> py, add family members
-rename analysis.py to topic_extraction.py
-transfer doc topic info merging in analysis.ipynb to analysis.py
-rename analysis.ipynb to scratch.ipynb
-rename city_eda.ipynb to city_country_extraction.py


-relocate all files under src folder

ultimate goals: movement of persons (person importance over time), allies/enemies of countries

readings:social, nlp

brainstorming 1:
1-think on interesting research questions
2-think on overleaf + paper notes
3-think on nlp + gds application on our KG specifically
4-think on pure nlp for analysis

brainstorming 2:
start using edge weight (similarity measure, sentiment)?
only include countries for the sentiment analysis?
which topics turkey mentioned in over time? greece -> saudi arabia e.g.(for which topics countries become closer? add sentiment?)
political word embeddings type named entity embeddings
merge keywords with ne but this time not on countvectorizer for ke
adding keywords to KG as well (meaningful keywords from phrase extractor), store their embeddings as well where edge weight is mutual similarity
adding named entities to KG as well
adding document/paragraph sentiment to KG as well
adding sentiments to kg for 2nd goal?
including the sentence of paragraph redaction is in OR extracting amount of redaction
how to handle histroical countries? 
node embeddings from gds + doc2vec + bump chart as proof of concept
entity linking, then person->political view
co-reference resolution? neuralcoref by huggingface
source requires more processing
handle person who are not annotated with persName tag
threshold on cosine similarities for wikidata matching
increase cosine similarity threshold for sbert wikidata description match
replace abbr within text with full
using person, country, institution descriptions from wikipedia ?
sentence or paragraph level semantics and their projection and evaluation in space ?
event 
https://spacy.io/usage/linguistic-features#entity-lixnking
emotion detection